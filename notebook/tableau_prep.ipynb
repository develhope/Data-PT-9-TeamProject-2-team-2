{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d70376a3",
   "metadata": {},
   "source": [
    "## PARAMS & overview\n",
    "Ho centralizzato i path e definito gli output principali per preparare i file destinati a Tableau.\n",
    "Uso questo notebook per: caricare il file cleaned, applicare la rimozione outlier sul prezzo (IQR), creare il file riga-per-riga per la mappa e l'aggregato per dealer_region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f633e5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /Users/serenatempesta/Documents/Progetti/Data_Analysis/progetto_finale\n",
      "CLEANED_PATH exists? True\n",
      "PROCESSED_DIR: /Users/serenatempesta/Documents/Progetti/Data_Analysis/progetto_finale/data/processed\n",
      "MAPPINGS_DIR: /Users/serenatempesta/Documents/Progetti/Data_Analysis/progetto_finale/notebook/mappings\n"
     ]
    }
   ],
   "source": [
    "# PARAMS: definisco qui i path canonici (modificare solo se necessario)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# nota: assumo che il notebook sia in project_root/notebook/\n",
    "ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # se il notebook è altrove, aggiusta qui\n",
    "RAW_DIR = os.path.join(ROOT, \"data\", \"raw\")\n",
    "PROCESSED_DIR = os.path.join(ROOT, \"data\", \"processed\")\n",
    "MAPPINGS_DIR = os.path.join(ROOT, \"notebook\", \"mappings\")\n",
    "\n",
    "# file principali: uso il cleaned canonical fornito da Matteo (o presente in data/processed)\n",
    "CLEANED_PATH = os.path.join(PROCESSED_DIR, \"database_cleaned.csv\")\n",
    "OUT_AGG_PATH = os.path.join(PROCESSED_DIR, \"agg_by_dealer_region_for_tableau.csv\")\n",
    "OUT_CITY_PATH = os.path.join(PROCESSED_DIR, \"database_for_tableau_city_state.csv\")\n",
    "\n",
    "# controllo rapido — se il file cleaned non esiste prendo nota per ripristino\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"CLEANED_PATH exists?\", os.path.exists(CLEANED_PATH))\n",
    "print(\"PROCESSED_DIR:\", PROCESSED_DIR)\n",
    "print(\"MAPPINGS_DIR:\", MAPPINGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b446a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricato df shape: (23906, 13)\n",
      "Colonne presenti: ['Date', 'Customer Name', 'Gender', 'Annual Income', 'Dealer_Name', 'Company', 'Model', 'Engine', 'Transmission', 'Color', 'Price ($)', 'Body Style', 'Dealer_Region']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Dealer_Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Model</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Color</th>\n",
       "      <th>Price ($)</th>\n",
       "      <th>Body Style</th>\n",
       "      <th>Dealer_Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>Geraldine</td>\n",
       "      <td>Male</td>\n",
       "      <td>13500</td>\n",
       "      <td>Buddy Storbeck's Diesel Service Inc</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Expedition</td>\n",
       "      <td>DoubleÂ Overhead Camshaft</td>\n",
       "      <td>Auto</td>\n",
       "      <td>Black</td>\n",
       "      <td>26000</td>\n",
       "      <td>SUV</td>\n",
       "      <td>Middletown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>Gia</td>\n",
       "      <td>Male</td>\n",
       "      <td>1480000</td>\n",
       "      <td>C &amp; M Motors Inc</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>Durango</td>\n",
       "      <td>DoubleÂ Overhead Camshaft</td>\n",
       "      <td>Auto</td>\n",
       "      <td>Black</td>\n",
       "      <td>19000</td>\n",
       "      <td>SUV</td>\n",
       "      <td>Aurora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>Gianna</td>\n",
       "      <td>Male</td>\n",
       "      <td>1035000</td>\n",
       "      <td>Capitol KIA</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>Eldorado</td>\n",
       "      <td>Overhead Camshaft</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Red</td>\n",
       "      <td>31500</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>Greenville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Customer Name Gender  Annual Income  \\\n",
       "0 2022-01-02     Geraldine   Male          13500   \n",
       "1 2022-01-02           Gia   Male        1480000   \n",
       "2 2022-01-02        Gianna   Male        1035000   \n",
       "\n",
       "                           Dealer_Name   Company       Model  \\\n",
       "0  Buddy Storbeck's Diesel Service Inc      Ford  Expedition   \n",
       "1                     C & M Motors Inc     Dodge     Durango   \n",
       "2                          Capitol KIA  Cadillac    Eldorado   \n",
       "\n",
       "                      Engine Transmission  Color  Price ($) Body Style  \\\n",
       "0  DoubleÂ Overhead Camshaft         Auto  Black      26000        SUV   \n",
       "1  DoubleÂ Overhead Camshaft         Auto  Black      19000        SUV   \n",
       "2          Overhead Camshaft       Manual    Red      31500  Passenger   \n",
       "\n",
       "  Dealer_Region  \n",
       "0    Middletown  \n",
       "1        Aurora  \n",
       "2    Greenville  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carico il cleaned file in modo robusto (se esiste la colonna Date la converto)\n",
    "# Se CLEANED_PATH non è presente, intervenire prima di eseguire le celle successive.\n",
    "cols0 = pd.read_csv(CLEANED_PATH, nrows=0).columns.tolist()\n",
    "parse_arg = ['Date'] if 'Date' in cols0 else None\n",
    "\n",
    "df = pd.read_csv(CLEANED_PATH, parse_dates=parse_arg, low_memory=False)\n",
    "print(\"Caricato df shape:\", df.shape)\n",
    "print(\"Colonne presenti:\", df.columns.tolist())\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87d129",
   "metadata": {},
   "source": [
    "## Pulizia minima e regola outlier\n",
    "- Trasformo Price e Annual Income in numerici (rimuovo simboli).\n",
    "- Applico outlier detection **solo su Price** usando la regola IQR (1.5 * IQR).\n",
    "- Tengo due dataframe:\n",
    "  - `df` = originale (con outlier) — per audit;\n",
    "  - `df_no_outliers` = senza outlier sul prezzo — usato per salvare i file per Tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43571af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulizia price: valori nulli -> 0 | min/max -> 1200 85800\n",
      "Ho identificato 1449 outlier sul prezzo (IQR).\n",
      "Shape df_no_outliers: (22457, 16)\n"
     ]
    }
   ],
   "source": [
    "# Pulisco le colonne money e le converto in numerico (mantengo la colonna originale per controllo)\n",
    "def to_numeric_money(series):\n",
    "    # rimuovo simboli non numerici, gestisco valori vuoti\n",
    "    s = series.astype(str).str.replace(r\"[^\\d\\.\\-]\", \"\", regex=True)\n",
    "    s = s.replace(\"\", np.nan)\n",
    "    return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "# riconosco i nomi tipici delle colonne (tolleranza a varianti)\n",
    "price_cols = [c for c in df.columns if c.lower().strip() in (\"price ($)\",\"price\",\"price_$\",\"price($)\",\"price ($)\")]\n",
    "income_cols = [c for c in df.columns if c.lower().strip() in (\"annual income\",\"annual_income\",\"income\",\"annualincome\")]\n",
    "\n",
    "if not price_cols:\n",
    "    raise RuntimeError(\"Non trovo la colonna Price: controlla i nomi delle colonne nel dataset.\")\n",
    "PRICE_COL = price_cols[0]\n",
    "INCOME_COL = income_cols[0] if income_cols else None\n",
    "\n",
    "# creo colonne pulite\n",
    "# Ho chiamato le colonne _price_clean e _income_clean per non sovrascrivere i dati originali\n",
    "df[\"_price_clean\"] = to_numeric_money(df[PRICE_COL])\n",
    "if INCOME_COL:\n",
    "    df[\"_income_clean\"] = to_numeric_money(df[INCOME_COL])\n",
    "else:\n",
    "    df[\"_income_clean\"] = np.nan\n",
    "\n",
    "print(\"Pulizia price: valori nulli ->\", df[\"_price_clean\"].isna().sum(), \n",
    "      \"| min/max ->\", df[\"_price_clean\"].min(), df[\"_price_clean\"].max())\n",
    "\n",
    "# Outlier detection SOLO su price (IQR)\n",
    "q1 = df[\"_price_clean\"].quantile(0.25)\n",
    "q3 = df[\"_price_clean\"].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "\n",
    "# segnalo gli outlier in una colonna booleana; li escludo solo per i file di visualizzazione\n",
    "df[\"_price_outlier\"] = (df[\"_price_clean\"] < lower) | (df[\"_price_clean\"] > upper)\n",
    "n_outliers = int(df[\"_price_outlier\"].sum())\n",
    "print(f\"Ho identificato {n_outliers} outlier sul prezzo (IQR).\")\n",
    "\n",
    "# creo df_no_outliers usato per le esportazioni verso Tableau\n",
    "df_no_outliers = df[~df[\"_price_outlier\"]].copy()\n",
    "print(\"Shape df_no_outliers:\", df_no_outliers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd49b58",
   "metadata": {},
   "source": [
    "## Tableau Prep · Sezione finale\n",
    "Questa sezione produce i dataset aggregati per **Dealer_Region** necessari a costruire in Tableau una mappa del **rapporto tra prezzo medio per auto e reddito medio dell’acquirente**.  \n",
    "Output previsti:\n",
    "- `dealer_ratio_for_tableau.csv` → KPI per distretto\n",
    "- `dealer_ratio_for_tableau_citystate.csv` → KPI per distretto + `city_state_lookup` per geocodifica\n",
    "- `dealer_ratio_by_year_for_tableau.csv` → variante per analisi temporale anno su anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df872d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File 'database_cleaned_2.csv' non trovato in nessuna delle cartelle candidate: data/processed, data, /mnt/data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RAW_MAIN \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMAIN_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m non trovato in nessuna delle cartelle candidate: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m CANDIDATE_DIRS)\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CITYSTATE_FILE \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Non è bloccante per la pipeline, ma avvisiamo: servirà solo per city_state_lookup\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvviso: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCITYSTATE_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m non trovato. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProseguo senza city_state_lookup (Tableau userà solo Dealer_Region).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File 'database_cleaned_2.csv' non trovato in nessuna delle cartelle candidate: data/processed, data, /mnt/data"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a16915d",
   "metadata": {},
   "source": [
    "### Controlli di qualità essenziali\n",
    "Si effettua un controllo sintetico su null, valori negativi e numerosità dei distretti.  \n",
    "L’obiettivo è prevenire problemi in fase di visualizzazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eee5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === QC VELOCE ===\n",
    "qc = {\n",
    "    \"rows\": len(df),\n",
    "    \"cols\": len(df.columns),\n",
    "    \"null_rate_price\": float(df[\"Price ($)\"].isna().mean()),\n",
    "    \"null_rate_income\": float(df[\"Annual Income\"].isna().mean()),\n",
    "    \"neg_values_price\": int((df[\"Price ($)\"] < 0).sum()),\n",
    "    \"neg_values_income\": int((df[\"Annual Income\"] < 0).sum()),\n",
    "    \"dealer_regions\": int(df[\"Dealer_Region\"].nunique()),\n",
    "}\n",
    "print(\"QC summary:\", qc)\n",
    "\n",
    "# Normalizzazione: valori negativi non sono ammessi per prezzo e reddito\n",
    "df.loc[df[\"Price ($)\"] < 0, \"Price ($)\"] = np.nan\n",
    "df.loc[df[\"Annual Income\"] < 0, \"Annual Income\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8b23b",
   "metadata": {},
   "source": [
    "### Aggregazione per Dealer_Region e calcolo del ratio\n",
    "Si calcolano:\n",
    "- prezzo medio, mediana prezzo\n",
    "- reddito medio\n",
    "- numero di osservazioni per distretto\n",
    "- **price_to_income_ratio** = avg_price / avg_income\n",
    "- **ratio_quantile** per una color scale discreta in mappa\n",
    "\n",
    "Si aggiunge poi un lookup `city_state` per facilitare la geocodifica in Tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2de4e858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path risolti:\n",
      " - RAW_MAIN: /Users/serenatempesta/Documents/Progetti/Data_Analysis/progetto_finale/data/processed/database_cleaned_2.csv\n",
      " - CITYSTATE_FILE: /Users/serenatempesta/Documents/Progetti/Data_Analysis/progetto_finale/data/processed/database_for_tableau_city_state.csv\n"
     ]
    }
   ],
   "source": [
    "# === PATH RESOLUTION (repo-aware) ===\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Nomi file attesi in data/processed\n",
    "MAIN_NAME = \"database_cleaned_2.csv\"\n",
    "CITYSTATE_NAME = \"database_for_tableau_city_state.csv\"\n",
    "\n",
    "# Candidati BASE_DIR: se il notebook è in root o dentro /notebook\n",
    "candidate_roots = [Path(\".\"), Path(\"..\")]\n",
    "\n",
    "RAW_MAIN = None\n",
    "CITYSTATE_FILE = None\n",
    "\n",
    "for root in candidate_roots:\n",
    "    base_proc = (root / \"data\" / \"processed\").resolve()\n",
    "    base_data = (root / \"data\").resolve()\n",
    "    candidates = [\n",
    "        base_proc / MAIN_NAME,\n",
    "        base_data / MAIN_NAME,\n",
    "        Path(\"/mnt/data\") / MAIN_NAME,   # fallback per ambienti remoti\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            RAW_MAIN = c\n",
    "            break\n",
    "    candidates_city = [\n",
    "        base_proc / CITYSTATE_NAME,\n",
    "        base_data / CITYSTATE_NAME,\n",
    "        Path(\"/mnt/data\") / CITYSTATE_NAME,\n",
    "    ]\n",
    "    for c in candidates_city:\n",
    "        if c.exists():\n",
    "            CITYSTATE_FILE = c\n",
    "            break\n",
    "    if RAW_MAIN is not None:\n",
    "        break  # abbiamo abbastanza per procedere (CITYSTATE è opzionale)\n",
    "\n",
    "if RAW_MAIN is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"database_cleaned_2.csv non trovato. Atteso in 'data/processed' (o 'data'). \"\n",
    "        \"Verificare che il notebook sia lanciato dalla root del repo o da /notebook.\"\n",
    "    )\n",
    "\n",
    "print(\"Path risolti:\")\n",
    "print(\" - RAW_MAIN:\", RAW_MAIN)\n",
    "print(\" - CITYSTATE_FILE:\", CITYSTATE_FILE if CITYSTATE_FILE else \"non trovato (lookup opzionale)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95bcc996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD & TYPES ===\n",
    "# Scopo: caricare i dati puliti e tipizzare i campi critici usati da Tableau.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(RAW_MAIN, low_memory=False)\n",
    "\n",
    "# Campi richiesti dalla metrica e dalla mappa\n",
    "required_cols = [\"Dealer_Region\", \"Price ($)\", \"Annual Income\", \"Date\"]\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Colonne mancanti: {missing} nel file {RAW_MAIN.name}\")\n",
    "\n",
    "# Tipi coerenti\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df[\"Price ($)\"] = pd.to_numeric(df[\"Price ($)\"], errors=\"coerce\")\n",
    "df[\"Annual Income\"] = pd.to_numeric(df[\"Annual Income\"], errors=\"coerce\")\n",
    "\n",
    "# (Opzionale) carico il lookup per city/state se disponibile\n",
    "cs = None\n",
    "if CITYSTATE_FILE and CITYSTATE_FILE.exists():\n",
    "    cs = pd.read_csv(CITYSTATE_FILE, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c1a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dealer_Region</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>price_median</th>\n",
       "      <th>avg_income</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>price_to_income_ratio</th>\n",
       "      <th>ratio_quantile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aurora</td>\n",
       "      <td>28334.626837</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>834341.026837</td>\n",
       "      <td>3130</td>\n",
       "      <td>0.033960</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austin</td>\n",
       "      <td>28341.603628</td>\n",
       "      <td>23801.0</td>\n",
       "      <td>809496.730593</td>\n",
       "      <td>4135</td>\n",
       "      <td>0.035011</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greenville</td>\n",
       "      <td>28180.819054</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>823138.340793</td>\n",
       "      <td>3128</td>\n",
       "      <td>0.034236</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Janesville</td>\n",
       "      <td>27833.350955</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>827446.300183</td>\n",
       "      <td>3821</td>\n",
       "      <td>0.033638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Middletown</td>\n",
       "      <td>27856.338875</td>\n",
       "      <td>22750.0</td>\n",
       "      <td>818402.594309</td>\n",
       "      <td>3128</td>\n",
       "      <td>0.034037</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dealer_Region     avg_price  price_median     avg_income  n_obs  \\\n",
       "0        Aurora  28334.626837       23000.0  834341.026837   3130   \n",
       "1        Austin  28341.603628       23801.0  809496.730593   4135   \n",
       "2    Greenville  28180.819054       22500.0  823138.340793   3128   \n",
       "3    Janesville  27833.350955       23000.0  827446.300183   3821   \n",
       "4    Middletown  27856.338875       22750.0  818402.594309   3128   \n",
       "\n",
       "   price_to_income_ratio  ratio_quantile  \n",
       "0               0.033960               2  \n",
       "1               0.035011               5  \n",
       "2               0.034236               4  \n",
       "3               0.033638               1  \n",
       "4               0.034037               3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dealer_Region</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>price_median</th>\n",
       "      <th>avg_income</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>price_to_income_ratio</th>\n",
       "      <th>ratio_quantile</th>\n",
       "      <th>city_state_lookup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aurora</td>\n",
       "      <td>28334.626837</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>834341.026837</td>\n",
       "      <td>3130</td>\n",
       "      <td>0.033960</td>\n",
       "      <td>2</td>\n",
       "      <td>Aurora, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austin</td>\n",
       "      <td>28341.603628</td>\n",
       "      <td>23801.0</td>\n",
       "      <td>809496.730593</td>\n",
       "      <td>4135</td>\n",
       "      <td>0.035011</td>\n",
       "      <td>5</td>\n",
       "      <td>Austin, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greenville</td>\n",
       "      <td>28180.819054</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>823138.340793</td>\n",
       "      <td>3128</td>\n",
       "      <td>0.034236</td>\n",
       "      <td>4</td>\n",
       "      <td>Greenville, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Janesville</td>\n",
       "      <td>27833.350955</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>827446.300183</td>\n",
       "      <td>3821</td>\n",
       "      <td>0.033638</td>\n",
       "      <td>1</td>\n",
       "      <td>Janesville, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Middletown</td>\n",
       "      <td>27856.338875</td>\n",
       "      <td>22750.0</td>\n",
       "      <td>818402.594309</td>\n",
       "      <td>3128</td>\n",
       "      <td>0.034037</td>\n",
       "      <td>3</td>\n",
       "      <td>Middletown, USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dealer_Region     avg_price  price_median     avg_income  n_obs  \\\n",
       "0        Aurora  28334.626837       23000.0  834341.026837   3130   \n",
       "1        Austin  28341.603628       23801.0  809496.730593   4135   \n",
       "2    Greenville  28180.819054       22500.0  823138.340793   3128   \n",
       "3    Janesville  27833.350955       23000.0  827446.300183   3821   \n",
       "4    Middletown  27856.338875       22750.0  818402.594309   3128   \n",
       "\n",
       "   price_to_income_ratio  ratio_quantile city_state_lookup  \n",
       "0               0.033960               2       Aurora, USA  \n",
       "1               0.035011               5       Austin, USA  \n",
       "2               0.034236               4   Greenville, USA  \n",
       "3               0.033638               1   Janesville, USA  \n",
       "4               0.034037               3   Middletown, USA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === AGGREGATION · KPI PER MAPPA ===\n",
    "# Scopo: costruire i KPI per Dealer_Region necessari alla mappa in Tableau.\n",
    "# Output:\n",
    "#   - agg_region: KPI per distretto (avg_price, avg_income, ratio, n_obs, quantili)\n",
    "#   - agg_region_filtered: come sopra + city_state_lookup (se disponibile) e filtro su n_obs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Safety: la base df deve essere già caricata nella sezione Load (con le colonne richieste)\n",
    "required = [\"Dealer_Region\", \"Price ($)\", \"Annual Income\"]\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Mancano colonne per l'aggregazione: {missing}\")\n",
    "\n",
    "# Parametri default nel caso non siano già stati definiti sopra\n",
    "try:\n",
    "    MIN_OBS_PER_REGION\n",
    "except NameError:\n",
    "    MIN_OBS_PER_REGION = 1\n",
    "try:\n",
    "    N_QUANTILES\n",
    "except NameError:\n",
    "    N_QUANTILES = 5\n",
    "\n",
    "# Aggregazione per distretto\n",
    "agg_region = (\n",
    "    df.groupby(\"Dealer_Region\", dropna=False)\n",
    "      .agg(\n",
    "          avg_price=(\"Price ($)\", \"mean\"),\n",
    "          price_median=(\"Price ($)\", \"median\"),\n",
    "          avg_income=(\"Annual Income\", \"mean\"),\n",
    "          n_obs=(\"Price ($)\", \"count\"),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Ratio e gestione inf/zero\n",
    "agg_region[\"price_to_income_ratio\"] = agg_region[\"avg_price\"] / agg_region[\"avg_income\"]\n",
    "agg_region.loc[~np.isfinite(agg_region[\"price_to_income_ratio\"]), \"price_to_income_ratio\"] = np.nan\n",
    "\n",
    "# Quantili per color scale discreta\n",
    "try:\n",
    "    agg_region[\"ratio_quantile\"] = pd.qcut(\n",
    "        agg_region[\"price_to_income_ratio\"], q=N_QUANTILES, labels=False, duplicates=\"drop\"\n",
    "    ) + 1\n",
    "except ValueError:\n",
    "    agg_region[\"ratio_quantile\"] = np.nan\n",
    "\n",
    "# Filtro opzionale su numerosità (riduce rumore in mappa)\n",
    "agg_region_filtered = agg_region.loc[agg_region[\"n_obs\"] >= MIN_OBS_PER_REGION].copy()\n",
    "\n",
    "# city_state_lookup (lookup moda per distretto) se disponibile\n",
    "city_lookup = None\n",
    "if \"cs\" in globals() and isinstance(cs, pd.DataFrame) and \\\n",
    "   \"Dealer_Region\" in cs.columns and \"city_state\" in cs.columns:\n",
    "    base_cs = cs\n",
    "elif \"CITYSTATE_FILE\" in globals() and CITYSTATE_FILE and Path(CITYSTATE_FILE).exists():\n",
    "    base_cs = pd.read_csv(CITYSTATE_FILE, low_memory=False)\n",
    "else:\n",
    "    base_cs = None\n",
    "\n",
    "if base_cs is not None and \"Dealer_Region\" in base_cs.columns and \"city_state\" in base_cs.columns:\n",
    "    city_lookup = (\n",
    "        base_cs.groupby(\"Dealer_Region\", dropna=False)[\"city_state\"]\n",
    "               .agg(lambda x: x.mode().iat[0] if x.mode().size else np.nan)\n",
    "               .reset_index()\n",
    "               .rename(columns={\"city_state\": \"city_state_lookup\"})\n",
    "    )\n",
    "    agg_region_filtered = agg_region_filtered.merge(city_lookup, on=\"Dealer_Region\", how=\"left\")\n",
    "else:\n",
    "    agg_region_filtered[\"city_state_lookup\"] = np.nan\n",
    "\n",
    "# Controllo rapido\n",
    "display(agg_region.head(5))\n",
    "display(agg_region_filtered.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e18456eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PATCH Stati per geocodifica ===\n",
    "# Nota per il team:\n",
    "# Molte delle città dei dealer district hanno nomi ambigui (negli USA lo stesso nome esiste in più stati).\n",
    "# Tableau Public Web non consente di risolvere queste ambiguità manualmente, quindi abbiamo scelto\n",
    "# uno Stato a caso tra le possibilità. Questa scelta è convenzionale e serve solo a permettere\n",
    "# la geocodifica in Tableau, non riflette la posizione reale dei dealer.\n",
    "\n",
    "city_to_state = {\n",
    "    \"Aurora\": \"Illinois\",\n",
    "    \"Austin\": \"Texas\",\n",
    "    \"Greenville\": \"South Carolina\",\n",
    "    \"Janesville\": \"Wisconsin\",\n",
    "    \"Middletown\": \"Connecticut\",\n",
    "    \"Pasco\": \"Washington\",\n",
    "    \"Scottsdale\": \"Arizona\"\n",
    "}\n",
    "\n",
    "# Aggiungiamo la colonna State basata sulla mappatura manuale\n",
    "if \"City\" in agg_region_filtered.columns:\n",
    "    agg_region_filtered[\"State\"] = agg_region_filtered[\"City\"].map(city_to_state)\n",
    "else:\n",
    "    print(\"Attenzione: la colonna 'City' non esiste in agg_region_filtered. Verificare pipeline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b70c51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export completato:\n",
      "→ /Users/serenatempesta/Documents/Progetti/Data_Analysis/progetto_finale/data/processed/dealer_ratio_for_tableau.csv\n",
      "→ /Users/serenatempesta/Documents/Progetti/Data_Analysis/progetto_finale/data/processed/dealer_ratio_for_tableau_citystate.csv\n",
      "Export completato:\n",
      "→ /Users/serenatempesta/Documents/Progetti/Data_Analysis/progetto_finale/data/processed/dealer_ratio_for_tableau.csv\n",
      "→ /Users/serenatempesta/Documents/Progetti/Data_Analysis/progetto_finale/data/processed/dealer_ratio_for_tableau_citystate.csv\n",
      "Export dir: /Users/serenatempesta/Documents/Progetti/Data_Analysis/progetto_finale/data/processed\n"
     ]
    }
   ],
   "source": [
    "# === EXPORT CSV · MAPPA STATICA ===\n",
    "# Scopo: salvare i dataset finali per Tableau nella cartella ufficiale del repo: data/processed\n",
    "# Requisiti: 'agg_region' e 'agg_region_filtered' sono stati creati nella cella \"AGGREGATION · KPI PER MAPPA\".\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Individuazione directory export (root repo → data/processed)\n",
    "here = Path.cwd().resolve()\n",
    "candidates = [here, here.parent, here.parent.parent]\n",
    "repo_root = None\n",
    "for base in candidates:\n",
    "    if (base / \"data\" / \"processed\").exists():\n",
    "        repo_root = base\n",
    "        break\n",
    "if repo_root is None:\n",
    "    repo_root = here\n",
    "\n",
    "OUT_DIR = (repo_root / \"data\" / \"processed\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2) Safety check\n",
    "if \"agg_region\" not in globals() or \"agg_region_filtered\" not in globals():\n",
    "    raise RuntimeError(\"Aggregazioni mancanti: eseguire prima 'AGGREGATION · KPI PER MAPPA'.\")\n",
    "\n",
    "# 3) Normalizzazione per geocodifica in Tableau \n",
    "# - Creiamo due colonne pulite: Country e City (il web authoring geocodifica bene City+Country)\n",
    "if \"city_state_lookup\" in agg_region_filtered.columns:\n",
    "    # uniformiamo il country\n",
    "    tmp = (\n",
    "        agg_region_filtered[\"city_state_lookup\"]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.replace(r\",\\s*USA$\", \", United States\", regex=True)\n",
    "    )\n",
    "    # City = parte prima della virgola \n",
    "    agg_region_filtered[\"City\"] = tmp.str.split(\",\").str[0].str.strip()\n",
    "    # Country = parte dopo la virgola, oppure \"United States\" di default\n",
    "    c2 = tmp.str.split(\",\").str[1].fillna(\"United States\").str.strip()\n",
    "    c2 = c2.replace(\"\", \"United States\")\n",
    "    agg_region_filtered[\"Country\"] = c2\n",
    "\n",
    "    # Drop eventuale colonna “clean” precedente per evitare duplicati/confusione\n",
    "    if \"city_state_lookup_clean\" in agg_region_filtered.columns:\n",
    "        agg_region_filtered.drop(columns=[\"city_state_lookup_clean\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# 4) Salvataggi finali \n",
    "out_dist = OUT_DIR / \"dealer_ratio_for_tableau.csv\"                 # KPI per distretto\n",
    "out_dist_city = OUT_DIR / \"dealer_ratio_for_tableau_citystate.csv\"  # KPI + City/Country\n",
    "\n",
    "agg_region.to_csv(out_dist, index=False)\n",
    "agg_region_filtered.to_csv(out_dist_city, index=False)\n",
    "\n",
    "print(\"Export completato:\")\n",
    "print(\"→\", out_dist.resolve())\n",
    "print(\"→\", out_dist_city.resolve())\n",
    "\n",
    "# 4) Salvataggi finali\n",
    "out_dist = OUT_DIR / \"dealer_ratio_for_tableau.csv\"                 # KPI per distretto\n",
    "out_dist_city = OUT_DIR / \"dealer_ratio_for_tableau_citystate.csv\"  # KPI + city_state_lookup\n",
    "\n",
    "agg_region.to_csv(out_dist, index=False)\n",
    "agg_region_filtered.to_csv(out_dist_city, index=False)\n",
    "\n",
    "print(\"Export completato:\")\n",
    "print(\"→\", out_dist.resolve())\n",
    "print(\"→\", out_dist_city.resolve())\n",
    "print(\"Export dir:\", OUT_DIR.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
