{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b02fc70f",
   "metadata": {},
   "source": [
    "Ricerca e controllo per possibili outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e4634",
   "metadata": {},
   "source": [
    "Import delle librerie necessarie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "375abb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc2c8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88065a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carico il cleaned file da: /Users/serenatempesta/Documents/Progetti/Data_Analysis/progetto_finale/data/processed/database_cleaned.csv\n",
      "Shape: (23906, 13)\n",
      "Colonne disponibili: ['Date', 'Customer Name', 'Gender', 'Annual Income', 'Dealer_Name', 'Company', 'Model', 'Engine', 'Transmission', 'Color', 'Price ($)', 'Body Style', 'Dealer_Region']\n",
      "Usata colonna reddito individuata: Annual Income\n",
      "\n",
      "_price_clean non-null: 23906   nulls: 0\n",
      "_income_clean non-null: 23906   nulls: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price ($)</th>\n",
       "      <th>_price_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26000</td>\n",
       "      <td>26000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19000</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31500</td>\n",
       "      <td>31500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14000</td>\n",
       "      <td>14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24500</td>\n",
       "      <td>24500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price ($)  _price_clean\n",
       "0      26000         26000\n",
       "1      19000         19000\n",
       "2      31500         31500\n",
       "3      14000         14000\n",
       "4      24500         24500\n",
       "5      12000         12000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>_income_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13500</td>\n",
       "      <td>13500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1480000</td>\n",
       "      <td>1480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1035000</td>\n",
       "      <td>1035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13500</td>\n",
       "      <td>13500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465000</td>\n",
       "      <td>1465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>850000</td>\n",
       "      <td>850000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Annual Income  _income_clean\n",
       "0          13500          13500\n",
       "1        1480000        1480000\n",
       "2        1035000        1035000\n",
       "3          13500          13500\n",
       "4        1465000        1465000\n",
       "5         850000         850000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_statistiche _price_clean:\n",
      "count    23906.000000\n",
      "mean     28090.247846\n",
      "std      14788.687608\n",
      "min       1200.000000\n",
      "25%      18001.000000\n",
      "50%      23000.000000\n",
      "75%      34000.000000\n",
      "max      85800.000000\n",
      "Name: _price_clean, dtype: float64\n",
      "\n",
      "Fatto: df_clean pronto. Uso df_clean['Price'] e df_clean['Annual Income'] per le celle successive.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Nota per i colleghi (Serena): normalizzo qui le colonne Price e Annual Income\n",
    "# - leggo il file cleaned (usa CLEANED_PATH se già definito nel notebook)\n",
    "# - pulisco \"Price ($)\" e \"Annual Income\" in colonne numeriche _price_clean e _income_clean\n",
    "# - creo le colonne canonicali 'Price' e 'Annual Income' così il resto del notebook non va toccato\n",
    "# ---------------------------------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# percorso file (usa CLEANED_PATH se è stato definito altrove nel notebook)\n",
    "try:\n",
    "    CLEANED_PATH\n",
    "except NameError:\n",
    "    CLEANED_PATH = os.path.join(\"data\", \"processed\", \"database_cleaned.csv\")\n",
    "\n",
    "print(f\"Carico il cleaned file da: {CLEANED_PATH}\")\n",
    "if not os.path.exists(CLEANED_PATH):\n",
    "    raise FileNotFoundError(f\"Non trovo {CLEANED_PATH}. Assicuratevi che il file esista o che il path sia corretto.\")\n",
    "\n",
    "# carico e mostro shape/prime colonne per controllo rapido\n",
    "df_tmp = pd.read_csv(CLEANED_PATH, low_memory=False)\n",
    "print(\"Shape:\", df_tmp.shape)\n",
    "print(\"Colonne disponibili:\", list(df_tmp.columns))\n",
    "\n",
    "# colonna prezzo nota dal dataset\n",
    "price_col = \"Price ($)\"\n",
    "# possibili nomi per il reddito annuale (se presenti)\n",
    "income_candidates = [c for c in df_tmp.columns if \"annual income\" in c.lower() or \"income\" in c.lower()]\n",
    "\n",
    "# controllo presenza colonne fondamentali\n",
    "if price_col not in df_tmp.columns:\n",
    "    raise KeyError(f\"Attenzione: mi aspettavo la colonna {price_col!r} nel cleaned dataset ma non è presente. Colonne trovate: {list(df_tmp.columns)}\")\n",
    "\n",
    "# funzione di pulizia standard (rimuove $, virgole, spazi e converte a numerico)\n",
    "def to_numeric_clean(s):\n",
    "    return pd.to_numeric(s.astype(str).str.replace(r\"[\\$,]\", \"\", regex=True).str.replace(r\"\\s+\", \"\", regex=True), errors=\"coerce\")\n",
    "\n",
    "# applico la pulizia al prezzo\n",
    "df_tmp[\"_price_clean\"] = to_numeric_clean(df_tmp[price_col])\n",
    "\n",
    "# se troviamo una colonna income la puliamo, altrimenti creiamo la colonna con NaN\n",
    "if income_candidates:\n",
    "    # scegliamo la prima candidata rilevata\n",
    "    income_col = income_candidates[0]\n",
    "    df_tmp[\"_income_clean\"] = to_numeric_clean(df_tmp[income_col])\n",
    "    print(f\"Usata colonna reddito individuata: {income_col}\")\n",
    "else:\n",
    "    income_col = None\n",
    "    df_tmp[\"_income_clean\"] = pd.NA\n",
    "    print(\"Nessuna colonna reddito trovata automaticamente; _income_clean sarà vuota (NaN).\")\n",
    "\n",
    "# report rapido per verificare che la conversione sia andata a buon fine\n",
    "print(\"\\n_price_clean non-null:\", int(df_tmp[\"_price_clean\"].notna().sum()),\n",
    "      \"  nulls:\", int(df_tmp[\"_price_clean\"].isna().sum()))\n",
    "print(\"_income_clean non-null:\", int(df_tmp[\"_income_clean\"].notna().sum()),\n",
    "      \"  nulls:\", int(df_tmp[\"_income_clean\"].isna().sum()))\n",
    "\n",
    "display(df_tmp[[price_col, \"_price_clean\"]].head(6))\n",
    "if income_col:\n",
    "    display(df_tmp[[income_col, \"_income_clean\"]].head(6))\n",
    "\n",
    "print(\"\\n_statistiche _price_clean:\")\n",
    "print(df_tmp[\"_price_clean\"].describe())\n",
    "\n",
    "# creo colonne canonicali che il resto del notebook si aspetta\n",
    "df_tmp[\"Price\"] = df_tmp[\"_price_clean\"]\n",
    "df_tmp[\"Annual Income\"] = df_tmp[\"_income_clean\"]\n",
    "\n",
    "# rendo il dataframe disponibile con nome atteso dalle celle successive\n",
    "df_clean = df_tmp\n",
    "\n",
    "print(\"\\nFatto: df_clean pronto. Uso df_clean['Price'] e df_clean['Annual Income'] per le celle successive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000d43d0",
   "metadata": {},
   "source": [
    "Inizio della parte di ricerca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fa273da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[serena] Using cleaned file: /Users/serenatempesta/Documents/Progetti/Data_Analysis/progetto_finale/data/processed/database_cleaned.csv\n",
      "[serena] Shape: (23906, 13)\n",
      "[serena] Columns: ['Date', 'Customer Name', 'Gender', 'Annual Income', 'Dealer_Name', 'Company', 'Model', 'Engine', 'Transmission', 'Color', 'Price ($)', 'Body Style', 'Dealer_Region']\n",
      "[serena] Building _price_clean from column: Price ($)\n",
      "[serena] Impostata/aggiornata colonna canonical 'Price' a partire da _price_clean.\n",
      "[serena] Building _income_clean from column: Annual Income\n",
      "\n",
      "[serena] Verifica rapida:\n",
      " - non-null _price_clean: 23906  / totale: 23906\n",
      " - non-null Price: 23906  / totale: 23906\n",
      " - non-null _income_clean: 23906\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price ($)</th>\n",
       "      <th>Price</th>\n",
       "      <th>_price_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26000</td>\n",
       "      <td>26000</td>\n",
       "      <td>26000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19000</td>\n",
       "      <td>19000</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31500</td>\n",
       "      <td>31500</td>\n",
       "      <td>31500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14000</td>\n",
       "      <td>14000</td>\n",
       "      <td>14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24500</td>\n",
       "      <td>24500</td>\n",
       "      <td>24500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14000</td>\n",
       "      <td>14000</td>\n",
       "      <td>14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42000</td>\n",
       "      <td>42000</td>\n",
       "      <td>42000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price ($)  Price  _price_clean\n",
       "0      26000  26000         26000\n",
       "1      19000  19000         19000\n",
       "2      31500  31500         31500\n",
       "3      14000  14000         14000\n",
       "4      24500  24500         24500\n",
       "5      12000  12000         12000\n",
       "6      14000  14000         14000\n",
       "7      42000  42000         42000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[serena] df_clean pronto: le celle successive possono ora usare df_clean['Price'] e df_clean['Annual Income'] senza KeyError.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Serena -> caricamento pulito + normalizzazione Price/Income\n",
    "# - cerco il cleaned file in percorsi standard\n",
    "# - leggo il file in modo robusto\n",
    "# - pulisco \"Price ($)\" in _price_clean e creo la colonna canonical 'Price'\n",
    "# - pulisco eventuale colonna reddito e creo 'Annual Income'\n",
    "# - stampo report sintetico per controllo rapido\n",
    "# ---------------------------------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# definizione percorsi: cerco il cleaned file in vari posti standard del progetto\n",
    "ROOT = os.path.abspath(os.getcwd())\n",
    "DATA_DIR = os.path.join(ROOT, \"data\")\n",
    "PROCESSED_DIR = os.path.join(DATA_DIR, \"processed\")\n",
    "\n",
    "candidates = [\n",
    "    os.path.join(DATA_DIR, \"database_cleaned_2.csv\"),\n",
    "    os.path.join(PROCESSED_DIR, \"database_cleaned_2.csv\"),\n",
    "    os.path.join(PROCESSED_DIR, \"database_cleaned.csv\"),\n",
    "    os.path.join(DATA_DIR, \"database_cleaned.csv\"),\n",
    "]\n",
    "\n",
    "# prendo CLEANED_PATH predefinito se è già stato definito altrove\n",
    "try:\n",
    "    CLEANED_PATH\n",
    "except NameError:\n",
    "    CLEANED_PATH = None\n",
    "\n",
    "if not CLEANED_PATH:\n",
    "    CLEANED_PATH = next((p for p in candidates if os.path.exists(p)), None)\n",
    "\n",
    "if not CLEANED_PATH:\n",
    "    raise FileNotFoundError(\n",
    "        \"Nessun file 'database_cleaned' trovato. Controlla dove Matteo ha salvato il file o rigenera il cleaned dataset. \"\n",
    "        \"Cercati questi percorsi: \" + \", \".join(candidates)\n",
    "    )\n",
    "\n",
    "print(f\"[serena] Using cleaned file: {CLEANED_PATH}\")\n",
    "df_clean = pd.read_csv(CLEANED_PATH, low_memory=False)\n",
    "\n",
    "# mostro shape e colonne per immediatezza\n",
    "print(\"[serena] Shape:\", df_clean.shape)\n",
    "print(\"[serena] Columns:\", list(df_clean.columns))\n",
    "\n",
    "# funzione di pulizia robusta per numerici che possono contenere $ , spazi, virgole\n",
    "def to_numeric_clean(series):\n",
    "    return pd.to_numeric(series.astype(str).str.replace(r\"[\\$,]\", \"\", regex=True).str.replace(r\"\\s+\", \"\", regex=True), errors=\"coerce\")\n",
    "\n",
    "# costruiamo _price_clean a partire da \"Price ($)\" se presente, altrimenti cerchiamo alternative\n",
    "if \"_price_clean\" not in df_clean.columns:\n",
    "    if \"Price ($)\" in df_clean.columns:\n",
    "        src = \"Price ($)\"\n",
    "    else:\n",
    "        # fallback: trova prima colonna che contiene 'price' o '$'\n",
    "        cand = [c for c in df_clean.columns if 'price' in c.lower() or '$' in c]\n",
    "        src = cand[0] if cand else None\n",
    "\n",
    "    if src is None:\n",
    "        print(\"[serena] ERRORE: nessuna colonna prezzo trovata automaticamente. Colonne disponibili:\")\n",
    "        print(list(df_clean.columns))\n",
    "        raise KeyError(\"Nessuna colonna prezzo trovata (cerco 'Price ($)' o colonne con 'price').\")\n",
    "    print(f\"[serena] Building _price_clean from column: {src}\")\n",
    "    df_clean[\"_price_clean\"] = to_numeric_clean(df_clean[src])\n",
    "else:\n",
    "    print(\"[serena] _price_clean già presente, lo uso così com'è.\")\n",
    "\n",
    "# assicuriamo la colonna canonical 'Price' per la compatibilità con le celle seguenti\n",
    "if \"Price\" not in df_clean.columns or df_clean[\"Price\"].isna().sum() > 0:\n",
    "    df_clean[\"Price\"] = df_clean[\"_price_clean\"]\n",
    "    print(\"[serena] Impostata/aggiornata colonna canonical 'Price' a partire da _price_clean.\")\n",
    "\n",
    "# reddito: cerchiamo colonne candidate e puliamo\n",
    "income_candidates = [c for c in df_clean.columns if \"annual income\" in c.lower() or \"income\" == c.lower() or \"income\" in c.lower()]\n",
    "if \"_income_clean\" not in df_clean.columns:\n",
    "    if income_candidates:\n",
    "        inc_src = income_candidates[0]\n",
    "        print(f\"[serena] Building _income_clean from column: {inc_src}\")\n",
    "        df_clean[\"_income_clean\"] = to_numeric_clean(df_clean[inc_src])\n",
    "        df_clean[\"Annual Income\"] = df_clean[\"_income_clean\"]\n",
    "    else:\n",
    "        df_clean[\"_income_clean\"] = pd.NA\n",
    "        print(\"[serena] Nessuna colonna reddito trovata automaticamente; _income_clean sarà NaN.\")\n",
    "\n",
    "# report rapido\n",
    "print(\"\\n[serena] Verifica rapida:\")\n",
    "print(\" - non-null _price_clean:\", int(df_clean[\"_price_clean\"].notna().sum()), \" / totale:\", len(df_clean))\n",
    "print(\" - non-null Price:\", int(df_clean[\"Price\"].notna().sum()), \" / totale:\", len(df_clean))\n",
    "if \"_income_clean\" in df_clean.columns:\n",
    "    print(\" - non-null _income_clean:\", int(df_clean[\"_income_clean\"].notna().sum()))\n",
    "\n",
    "display(df_clean[[c for c in [\"Price ($)\", \"Price\", \"_price_clean\"] if c in df_clean.columns]].head(8))\n",
    "\n",
    "print(\"\\n[serena] df_clean pronto: le celle successive possono ora usare df_clean['Price'] e df_clean['Annual Income'] senza KeyError.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11f7fd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numero di outlier con prezzo > 80000: 220\n",
      "Numero di outlier con prezzo < 9000: 6\n",
      "\n",
      "Dimensione del dataset originale: 23906\n",
      "Dimensione del dataset senza outlier: 23680\n"
     ]
    }
   ],
   "source": [
    "outlier_alti = df_clean[df_clean['Price'] > 80000]\n",
    "outlier_bassi = df_clean[df_clean['Price'] < 9000]\n",
    "num_outlier_alti = len(outlier_alti)\n",
    "num_outlier_bassi = len(outlier_bassi)\n",
    "print(f\"\\nNumero di outlier con prezzo > 80000: {num_outlier_alti}\")\n",
    "print(f\"Numero di outlier con prezzo < 9000: {num_outlier_bassi}\")\n",
    "df_no_outliers = df_clean[(df_clean['Price'] <= 80000) & (df_clean['Price'] >= 9000)]\n",
    "print(f\"\\nDimensione del dataset originale: {len(df_clean)}\")\n",
    "print(f\"Dimensione del dataset senza outlier: {len(df_no_outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc86bb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media: 830840.2851167071\n",
      "Mediana: 735000.0\n",
      "Massimo: 11200000\n",
      "Minimo: 10080\n",
      "       Annual Income\n",
      "14026       11200000\n",
      "15675        8000000\n",
      "6150         7650000\n",
      "9996         6800000\n",
      "22407        6600000\n",
      "11607        6500000\n",
      "7657         6460000\n",
      "8817         6400000\n",
      "14183        6400000\n",
      "4755         6240000\n",
      "       Annual Income\n",
      "23451          10080\n",
      "0              13500\n",
      "3              13500\n",
      "7              13500\n",
      "9              13500\n",
      "10             13500\n",
      "11             13500\n",
      "13             13500\n",
      "20             13500\n",
      "28             13500\n"
     ]
    }
   ],
   "source": [
    "df_clean.max()['Annual Income']\n",
    "df_clean.min()['Annual Income']\n",
    "df_clean['Annual Income'].mean()\n",
    "df_clean['Annual Income'].median()\n",
    "print(\"Media:\", df_clean['Annual Income'].mean())\n",
    "print(\"Mediana:\", df_clean['Annual Income'].median())\n",
    "print(\"Massimo:\",df_clean.max()['Annual Income'])\n",
    "print(\"Minimo:\",df_clean.min()['Annual Income'])\n",
    "top_10_income = df_clean.nlargest(10, 'Annual Income')\n",
    "print(top_10_income[['Annual Income']])\n",
    "bottom_10_income = df_clean.nsmallest(10, 'Annual Income')\n",
    "print(bottom_10_income[['Annual Income']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bd1d245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numero di outlier con salari > 7000000: 3\n",
      "Numero di outlier con salari < 100000: 5276\n",
      "\n",
      "Dimensione del dataset originale: 23906\n",
      "Dimensione del dataset senza outlier: 18627\n"
     ]
    }
   ],
   "source": [
    "outlier_salari_alti = df_clean[df_clean['Annual Income'] > 7000000]\n",
    "outlier_salari_bassi = df_clean[df_clean['Annual Income'] < 100000]\n",
    "num_outlier_salari_alti = len(outlier_salari_alti)\n",
    "num_outlier_salari_bassi = len(outlier_salari_bassi)\n",
    "print(f\"\\nNumero di outlier con salari > 7000000: {num_outlier_salari_alti}\")\n",
    "print(f\"Numero di outlier con salari < 100000: {num_outlier_salari_bassi}\")\n",
    "df_no_outliers = df_clean[(df_clean['Annual Income'] <= 7000000) & (df_clean['Annual Income'] >= 100000)]\n",
    "print(f\"\\nDimensione del dataset originale: {len(df_clean)}\")\n",
    "print(f\"Dimensione del dataset senza outlier: {len(df_no_outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72ed88d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Le 10 auto con il reddito annuale più alto:\n",
      "          Company          Model  Annual Income  Price\n",
      "14026  Oldsmobile        Bravada       11200000  26001\n",
      "15675  Mercedes-B        S-Class        8000000  85000\n",
      "6150      Hyundai         Sonata        7650000  21000\n",
      "9996          BMW           323i        6800000  15000\n",
      "22407     Mercury          Sable        6600000  39000\n",
      "11607        Ford        Mustang        6500000  25000\n",
      "7657       Toyota         Celica        6460000  14000\n",
      "8817      Mercury  Grand Marquis        6400000  71000\n",
      "14183      Nissan          Quest        6400000  32001\n",
      "4755     Chrysler       Concorde        6240000  42000\n",
      "\n",
      "Le 10 auto con il reddito annuale più basso:\n",
      "          Company        Model  Annual Income  Price\n",
      "13099  Volkswagen       Passat          13500  21000\n",
      "13097   Chevrolet     Cavalier          13500  20000\n",
      "13096  Mercedes-B        CL500          13500  22000\n",
      "13095        Ford     Explorer          13500  22000\n",
      "13091    Chrysler          LHS          13500  20001\n",
      "13086       Buick  Park Avenue          13500  29001\n",
      "13084       Honda       Accord          13500  19000\n",
      "13081       Honda     Passport          13500  27001\n",
      "11953     Pontiac   Bonneville          13500  19001\n",
      "23451    Infiniti          I30          10080  22801\n"
     ]
    }
   ],
   "source": [
    "top_10_redditi = df_clean.sort_values(by='Annual Income', ascending=False).head(10)\n",
    "print(\"\\nLe 10 auto con il reddito annuale più alto:\")\n",
    "print(top_10_redditi[['Company', 'Model', 'Annual Income', 'Price']])\n",
    "bottom_10_redditi = df_clean.sort_values(by='Annual Income', ascending=False).tail(10)\n",
    "print(\"\\nLe 10 auto con il reddito annuale più basso:\")\n",
    "print(bottom_10_redditi[['Company', 'Model', 'Annual Income', 'Price']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dbc6807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Le 10 auto con il prezzo più alto:\n",
      "          Company     Model  Annual Income  Price\n",
      "7068     Cadillac  Eldorado        1388000  85800\n",
      "17129    Cadillac  Eldorado        5046000  85601\n",
      "13605    Cadillac  Eldorado        1036000  85600\n",
      "358        Toyota      RAV4        1326000  85600\n",
      "9228         Audi        A6         497500  85500\n",
      "11330    Cadillac  Eldorado        1185000  85500\n",
      "17947    Cadillac  Eldorado        1414000  85400\n",
      "2661     Cadillac  Eldorado        1483000  85301\n",
      "11428      Toyota      RAV4        1053000  85300\n",
      "6530   Mercedes-B   S-Class         392250  85250\n",
      "\n",
      "Le 10 auto con il prezzo più basso:\n",
      "          Company     Model  Annual Income  Price\n",
      "12717  Volkswagen    Passat          13500   9000\n",
      "20711  Volkswagen    Passat         522000   9000\n",
      "23247  Volkswagen    Passat        1900000   9000\n",
      "8081     Plymouth      Neon         880000   9000\n",
      "14185        Ford    Taurus        2200000   4300\n",
      "13949        Ford  Explorer         680000   4200\n",
      "14020  Mercedes-B     CL500          13500   2200\n",
      "14010     Lincoln  Town car          13500   1700\n",
      "13996  Mercedes-B   S-Class        1955000   1450\n",
      "13946        Ford    Taurus          13500   1200\n"
     ]
    }
   ],
   "source": [
    "top_10_auto = df_clean.sort_values(by='Price', ascending=False).head(10)\n",
    "print(\"\\nLe 10 auto con il prezzo più alto:\")\n",
    "print(top_10_auto[['Company', 'Model', 'Annual Income', 'Price']])\n",
    "bottom_10_auto = df_clean.sort_values(by='Price', ascending=False).tail(10)\n",
    "print(\"\\nLe 10 auto con il prezzo più basso:\")\n",
    "print(bottom_10_auto[['Company', 'Model', 'Annual Income', 'Price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d5d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Serena -> applicazione mapping categorical + pulizia base\n",
    "# - leggo eventuali mapping generati in notebook/mappings/*.csv\n",
    "# - normalizzo (trim, lowercase) e applico canonical dove disponibile\n",
    "# - mantengo raw->canonical fallback se mapping vuoti\n",
    "# ---------------------------------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# controllo df_clean in memoria\n",
    "if 'df_clean' not in globals():\n",
    "    raise RuntimeError(\"df_clean non esiste. Esegui prima la cella di caricamento/normalizzazione.\")\n",
    "\n",
    "MAP_DIR = os.path.join(\"notebook\", \"mappings\")\n",
    "os.makedirs(MAP_DIR, exist_ok=True)\n",
    "\n",
    "# colonne categorical da normalizzare (quelle che avevamo analizzato)\n",
    "cat_cols = ['Company', 'Dealer_Name', 'Model', 'Transmission', 'Gender', 'Customer Name', 'Dealer_Region', 'city_state']\n",
    "\n",
    "def canonicalize_column(df, col, map_dir=MAP_DIR):\n",
    "    \"\"\"Applica mapping se esiste mapping/<col>_mapping.csv altrimenti esegue trim/lower.\"\"\"\n",
    "    map_fn = os.path.join(map_dir, f\"{col}_mapping.csv\")\n",
    "    if os.path.exists(map_fn):\n",
    "        # legge mapping e usa canonical se presente, altrimenti fallback al raw normalizzato\n",
    "        m = pd.read_csv(map_fn).fillna('')\n",
    "        # assicuriamo colonne raw/canonical\n",
    "        if {'raw','canonical'}.issubset(m.columns):\n",
    "            # build dict (raw normalizzato -> canonical se non vuoto altrimenti raw)\n",
    "            d = {r.strip().lower(): (c.strip() if c.strip()!='' else r.strip()) for r,c in zip(m['raw'].astype(str), m['canonical'].astype(str))}\n",
    "            # applica\n",
    "            df[col + \"_mapped\"] = df[col].astype(str).str.strip().str.lower().map(d).fillna(df[col].astype(str).str.strip().str.lower())\n",
    "            return True\n",
    "    # fallback: trim + lower\n",
    "    df[col + \"_mapped\"] = df[col].astype(str).str.strip().str.lower()\n",
    "    return False\n",
    "\n",
    "# applica ai cat_cols presenti nel df\n",
    "for c in cat_cols:\n",
    "    if c in df_clean.columns:\n",
    "        used_map = canonicalize_column(df_clean, c)\n",
    "        print(f\"[serena] Colonna {c}: mapping applicato? {used_map}\")\n",
    "    else:\n",
    "        print(f\"[serena] Colonna {c}: non presente nel dataframe, salto.\")\n",
    "\n",
    "# breve controllo\n",
    "print(\"\\nEsempio valori canonical (per Company, Model, Dealer_Region se esistono):\")\n",
    "for c in ['Company','Model','Dealer_Region']:\n",
    "    mapped = c + \"_mapped\"\n",
    "    if mapped in df_clean.columns:\n",
    "        print(f\" - {mapped}: top 5 ->\")\n",
    "        display(df_clean[mapped].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad77360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Serena -> gestione missing, placeholder e outlier (semplice)\n",
    "# - sostituisco placeholder noti con NaN/John Doe già gestito\n",
    "# - rimuovo spazi, converto Price e Annual Income a numerico (se non già fatto)\n",
    "# - gestisco outlier su Price e Annual Income con winsorization 1%-99%\n",
    "# - stampo riepilogo e distribuzioni sintetiche\n",
    "# ---------------------------------------------------------\n",
    "import numpy as np\n",
    "\n",
    "# placeholder comuni che vogliamo considerare come NaN\n",
    "placeholders = ['', 'nan', 'none', 'unknown', 'n/a', 'na', 'john doe']\n",
    "\n",
    "# normalizzo stringhe su tutte le colonne stringa per uniformità (non distruttivo)\n",
    "for col in df_clean.select_dtypes(include='object').columns:\n",
    "    df_clean[col] = df_clean[col].astype(str).str.strip()\n",
    "\n",
    "# assicuriamo colonne numeriche pulite (se già esistono _price_clean / _income_clean le usiamo)\n",
    "if '_price_clean' not in df_clean.columns:\n",
    "    # prova a pulire da \"Price ($)\" o altro\n",
    "    if \"Price ($)\" in df_clean.columns:\n",
    "        src = \"Price ($)\"\n",
    "    else:\n",
    "        src = next((c for c in df_clean.columns if 'price' in c.lower()), None)\n",
    "    if src:\n",
    "        df_clean['_price_clean'] = pd.to_numeric(df_clean[src].astype(str).str.replace(r'[\\$,]', '', regex=True).str.replace(r'\\s+', '', regex=True), errors='coerce')\n",
    "    else:\n",
    "        df_clean['_price_clean'] = pd.NA\n",
    "\n",
    "if '_income_clean' not in df_clean.columns:\n",
    "    inc_src = next((c for c in df_clean.columns if 'annual income' in c.lower() or 'income' in c.lower()), None)\n",
    "    if inc_src:\n",
    "        df_clean['_income_clean'] = pd.to_numeric(df_clean[inc_src].astype(str).str.replace(r'[\\$,]', '', regex=True).str.replace(r'\\s+', '', regex=True), errors='coerce')\n",
    "    else:\n",
    "        df_clean['_income_clean'] = pd.NA\n",
    "\n",
    "# sostituisci placeholder con NaN\n",
    "for c in df_clean.columns:\n",
    "    if df_clean[c].dtype == object:\n",
    "        df_clean.loc[df_clean[c].str.lower().isin(placeholders), c] = pd.NA\n",
    "\n",
    "# Outlier: winsorization semplice (1%-99%) su _price_clean e _income_clean\n",
    "def winsorize_series(s, lower_q=0.01, upper_q=0.99):\n",
    "    if s.dropna().empty:\n",
    "        return s\n",
    "    lo = s.quantile(lower_q)\n",
    "    hi = s.quantile(upper_q)\n",
    "    return s.clip(lower=lo, upper=hi)\n",
    "\n",
    "if df_clean['_price_clean'].notna().sum() > 0:\n",
    "    df_clean['_price_clean_w'] = winsorize_series(df_clean['_price_clean'])\n",
    "else:\n",
    "    df_clean['_price_clean_w'] = df_clean['_price_clean']\n",
    "\n",
    "if df_clean['_income_clean'].notna().sum() > 0:\n",
    "    df_clean['_income_clean_w'] = winsorize_series(df_clean['_income_clean'])\n",
    "else:\n",
    "    df_clean['_income_clean_w'] = df_clean['_income_clean']\n",
    "\n",
    "# aggiorno colonne canonical per sicurezza\n",
    "df_clean['Price'] = df_clean['_price_clean_w']\n",
    "df_clean['Annual Income'] = df_clean['_income_clean_w']\n",
    "\n",
    "# report sintetico\n",
    "print(\"[serena] Price non-null:\", int(df_clean['Price'].notna().sum()), \" / \", len(df_clean))\n",
    "print(\"[serena] Annual Income non-null:\", int(df_clean['Annual Income'].notna().sum()), \" / \", len(df_clean))\n",
    "print(\"\\nPrice summary (after winsorization):\")\n",
    "print(df_clean['Price'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Serena -> salvo versione finale cleaned per condivisione con il team / visualizzazione\n",
    "# - creo data/processed (se non esiste)\n",
    "# - salvo database_cleaned_2.csv\n",
    "# - stampo quick-check per conferma\n",
    "# ---------------------------------------------------------\n",
    "import os\n",
    "\n",
    "OUT_DIR = os.path.join(\"data\", \"processed\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "OUT_FN = \"database_cleaned_2.csv\"\n",
    "OUT_PATH = os.path.join(OUT_DIR, OUT_FN)\n",
    "\n",
    "# controllo df_clean\n",
    "if 'df_clean' not in globals():\n",
    "    raise RuntimeError(\"df_clean non esiste. Esegui prima le celle di cleaning.\")\n",
    "\n",
    "# salvo (index=False)\n",
    "df_clean.to_csv(OUT_PATH, index=False)\n",
    "print(f\"[serena] Saved cleaned dataset here: {OUT_PATH}\")\n",
    "\n",
    "# info quick-check\n",
    "print(\"[serena] File size (bytes):\", os.path.getsize(OUT_PATH))\n",
    "print(\"[serena] Head (preview):\")\n",
    "display(df_clean.head(5))\n",
    "\n",
    "# suggerimento: stampare qui le colonne finali utili per analisi/visual (es. dealer_region_mapped, city_state)\n",
    "print(\"\\n[serena] Colonne finali principali:\", [c for c in df_clean.columns if c in ['dealer_region_mapped','city_state','Company_mapped','Model_mapped','Price','Annual Income']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
